\section{Background}\label{sec:background}

The reader who is familiar with a two-context sequent calculus presentation of intuitionistic linear logic may skip \cref{sec:linear-logic}.

\subsection{Linear logic}\label{sec:linear-logic}

Like a good witness, traditional intuitionistic logic is concerned only with facts.
Facts are \vocab{persistent};
% Traditional intuitionistic logic is concerned with the \emph{truth} of propositions.
% Truths are \wc{forever};
having proved a proposition true, there is no \wc{harm}[\st{cost}] in reusing or even forgetting the proof.
Traditional intuitionistic logic therefore validates several structural principles: \vocab{contraction}, that hypotheses may be duplicated; \vocab{weakening}, that irrelevant hypotheses may be ignored; and \vocab{exchange}, that the order of hypotheses is unimportant.
% Such hypotheses are said to be \vocab{persistent}.

Linear logic~\autocite{Girard:TCS87}, on the other hand, treats proofs as precious\fxnote{, nonrenewable} resources.
Accordingly, linear logic cannot validate the contraction and weakening principles: resources should be neither freely duplicated (as\fxnote{\ \st{they would be}} with contraction) nor freely discarded (as\fxnote{\ \st{they would be}} with weakening).
The order of resources remains unimportant, however, so linear logic does validate the exchange principle.
Such resources are said to be \vocab{ephemeral}.

We will now review a sequent calculus for intuitionistic linear logic from the judgmental reconstruction by~\textcite{Chang+:CMU03}; our presentation is also heavily indebted to lectures by \textcite{Pfenning:816}.

The main judgment is a linear hypothetical judgment, or \vocab{sequent}, which states that by using resources~$A_1, \dotsc, A_n$ we can obtain resource~$A$:%
\begin{equation*}
  \underbrace{A_1, \dotsc, A_n}_{\textstyle \lctx} \seq A \:.
\end{equation*}
Because resources may be permuted but neither duplicated nor discarded, the context of resources~$A_1, \dotsc, A_n$ is treated as a multiset.
Following tradition, we use the metavariable~$\lctx$ to stand for an arbitrary context of resources.

\NewDocumentCommand{\lmatch}{O{} m}{\lctx#1, #2}%
\ExplSyntaxOn
\NewDocumentCommand{\lfill}{O{} m}{
  \lctx#1\tl_if_empty:nF{#2}{, #2}
}
\ExplSyntaxOff
%

\subsubsection{Judgmental rules}\label{sec:judgmental-rules}

What are the rules for obtaining and using resources?
One way to obtain a resource $A$ is to use it directly.
Dually, if we can use some of our resources to obtain an $A$, then we are justified in later using that $A$\fxnote{\ \st{along with the remaining resources}}.
These judgmental principles are expressed by the identity and cut rules\footnote{The identity and cut rules can in fact be shown to be admissible~\autocites{Chang+:CMU03}{Pfenning:816Identity}, but we postpone discussion of this to \cref{sec:linear-lp}.}, respectively:
\begin{mathpar}
  \infer[\lab{id$_A$}]{A \seq A}{
    }
  \and
  \infer[\lab{cut$_A$}]{\lmatch[']{\lctx} \seq C}{
    \lctx \seq A &
    \lfill[']{A} \seq C} \:.
\end{mathpar}
Notice that the identity rule uses only an $A$; allowing any other resources on the sequent's left would cause them to be incorrectly disposed here.

\subsubsection{Propositional connectives}\label{sec:prop-conn}

In addition to the judgmental rules of identity and cut, the sequent calculus contains right and left rules that give meaning to each propositional connective.
% A proof of $A \lolli B$ is a plan for using resource $A$ to achieve goal $B$.
For instance, the \wc{linear implication} $A \lolli B$ (pronounced \enquote{$A$ linearly implies $B$} or \enquote{$A$ lolli $B$}) internalizes the linear hypothetical judgment as a proposition: a proof of $A \lolli B$ is a plan for using resource $A$ to obtain resource $B$.
% To make our plan, we presume to have resource $A$ and show how to acheive $B$.
To obtain such a plan, we can presume to have an $A$ available for use and show how to obtain a $B$:
\begin{equation*}
  \infer[\rlab{{\lolli}}]{\lctx \seq A \lolli B}{
    \lctx, A \seq B}
  \:.
\end{equation*}
% Conversely, we can use our plan to produce $B$ if we can obtain an $A$.
Conversely, if we can obtain an $A$, then we can carry out, \ie\ use, our plan to make a $B$ available for use:
% To use our plan, we must first obtain $A$
\begin{equation*}
  \infer[\llab{{\lolli}}]{\lmatch[']{\lctx'_A, A \lolli B} \seq C}{
    \lctx'_A \seq A &
    \lfill[']{B} \seq C}
  \:.
\end{equation*}
Thus, the right and left rules explain how to obtain and use, respectively, the resource $A \lolli B$.

The resource $A \tensor B$ (pronounced \enquote{$A$ tensor $B$}) is a pair of the resources $A$ and $B$.
Once again, the right and left rules give meaning to $A \tensor B$:
\begin{mathpar}
  \infer[\rlab{{\tensor}}]{\lctx_1, \lctx_2 \seq A \tensor B}{
    \lctx_1 \seq A &
    \lctx_2 \seq B}
  \and
  \infer[\llab{{\tensor}}]{\lmatch[']{A \tensor B} \seq C}{
    \lfill[']{A, B} \seq C}
\end{mathpar}
To obtain an $A \tensor B$, we must use some of our resources to obtain an $A$ and the rest to obtain a $B$.
To use an $A \tensor B$, we must use \emph{both} an $A$ and a $B$: using only one would cause the resources that went into obtaining the other to be incorrectly disposed.
%These \wc{properties} are expressed in the right and left rules, respectively:
Thus, $A \tensor B$ is a multiplicative conjunction in which both $A$ and $B$ must be used.

A different, additive form of conjunction is given by $A \with B$ (pronounced~\enquote{$A$ with~$B$}):
\begin{mathpar}
  \infer[\rlab{{\with}}]{\lctx \seq A \with B}{
    \lctx \seq A &
    \lctx \seq B}
  \and
  \infer[{\llab{{\with}}[1]}]{\lmatch[']{A \with B} \seq C}{
    \lfill[']{A} \seq C}
  \and
  \infer[{\llab{{\with}}[2]}]{\lmatch[']{A \with B} \seq C}{
    \lfill[']{B} \seq C}
\end{mathpar}
To obtain an $A \with B$, we must obtain an $A$ and a $B$ using \emph{all} of our resources, $\lctx$, in each case.
To use an $A \with B$, we must then choose exactly one of $A$ and $B$ to use; using both would be an underhanded duplication of the resources $\lctx$.

The rules for the additive disjunction $A \llor B$ are dual to those for $A \with B$:
\begin{mathpar}
  \infer[{\rlab{{\llor}}[1]}]{\lctx \seq A \llor B}{
    \lctx \seq A}
  \and
  \infer[{\rlab{{\llor}}[2]}]{\lctx \seq A \llor B}{
    \lctx \seq B}
  \and
  \infer[\llab{{\llor}}]{\lmatch[']{A \llor B} \seq C}{
    \lfill[']{A} \seq C &
    \lfill[']{B} \seq C}
\end{mathpar}
A resource $A \llor B$ is thus either an $A$ or a $B$.
When using a $A \llor B$, we must therefore be prepared to use whichever one it may be.
% This time, instead of choosing one of $A$ and $B$ when using $A \llor B$, the environment has made that choice for us; we must be prepared for either case.

\subsubsection{First-order quantifiers}\label{sec:first-order-quant}

\NewDocumentCommand{\univq}{u: u.}{\forall #1{:}#2.\,}
\ExplSyntaxOn
\NewDocumentCommand{\existq}{>{\SplitArgument{1}{:}}u.}{% \existq_:n {#1}}
% \NewDocumentCommand{\existq_:n}{>{\SplitArgument{1}{:}}m}{
  \exists \use_i:nn #1
  \exp_args:No \IfValueT { \use_ii:nn #1 }
    { \mathord{\colon} \use_ii:nn #1 }
  .\,
}
\ExplSyntaxOff
\NewDocumentCommand{\tctx}{}{\Psi}
\NewDocumentCommand{\subst}{m m}{[#1]#2}
% We can also include first-order universal and existential quantifiers, $\univq x:\tau.A$ and $\existq x:\tau.A$.
Linear logic also has first-order universal and existential quantifiers, $\univq x:\tau.A$ and $\existq x:\tau.A$.
% The sequent is extended with a context, $\tctx$, of parameters $x_i{:}\tau_i$ so that it becomes $\tctx ; \lctx \seq A$.
The sequent is extended with a context of parameter typings, $x_i{:}\tau_i$:
\begin{equation*}
  \underbrace{x_1{:}\tau_1, \dotsc, x_n{:}\tau_n}_{\displaystyle \tctx} \;;\, \lctx \seq A \:.
\end{equation*}
To match the new form of sequent, all previously presented rules are uniformly modified to include a parameter context $\tctx$ in their premises and conclusion.

Only the rules for the quantifiers directly affect the parameter context.
They are the same as for traditional intuitionistic logic except that the quantifiers are ephemeral:
% The inference rules for quantifiers are then the same as for intuitionistic logic, except that the quantifiers are \wc{ephemeral}[\st{consumed upon use}]:
\begin{mathpar}
  \infer[\rlab{\forall}]{\tctx ; \lctx \seq \univq x:\tau. A_x}{
    \tctx, x{:}\tau ; \lctx \seq A_x}
  \and
  \infer[\llab{\forall}]{\tctx ; \lmatch[']{\univq x:\tau. A_x} \seq C}{
    \tctx \seq M : \tau &
    \tctx ; \lfill[']{\subst{M/x}{A_x}} \seq C}
  \\
  \infer[\rlab{\exists}]{\tctx ; \lctx \seq \existq x:\tau. A_x}{
    \tctx \seq M : \tau &
    \tctx ; \lctx \seq \subst{M/x}{A_x}}
  \and
  \infer[\llab{\exists}]{\tctx ; \lmatch[']{\existq x:\tau. A_x} \seq C}{
    \tctx, x{:}\tau ; \lfill[']{A_x} \seq C}
\end{mathpar}

\subsubsection{Persistence}\label{sec:persistence}

Even in resource-centric linear logic, we sometimes want to express persistent facts.
% Finally, even in linear logic we sometimes want to allow a controlled degree of persistence.
% % certain kinds of hypotheses to be duplicated or ignored in a controlled way.
To do so, we introduce a new judgment, $A \pers$, for proofs that may not depend on ephemeral resources.
% These hypotheses are called \vocab{valid} because they may not depend on linear resources.
% To do so, we introduce a new judgment, $B \valid$, for these persistent hypotheses.
The sequent is extended with a context of $\pers$ antecedents:
% that admits the contraction and weakening principles:
\begin{equation*}
  % \underbrace{x_1{:}\tau_1, \dotsc, x_\ell{:}\tau_\ell}_{\displaystyle \tctx} \,; \underbrace{B_1, \dotsc, B_m}_{\displaystyle \uctx} \,; \underbrace{A_1, \dotsc, A_n}_{\displaystyle \lctx} \seq A \:.
  \tctx \,;\, \underbrace{A_1, \dotsc, A_n}_{\displaystyle \uctx} \;;\, \lctx \seq A \:.
\end{equation*}
Because they may not depend on ephemeral resources, there is no harm in duplicating or discarding $\pers$ antecedents.
The persistent context~$\uctx$ therefore admits contraction and weakening (as well as exchange).

Consequently, we can
% Because persistent facts may be reused indefinitely, we may
copy a fact and use it as an ephemeral resource.
On the other hand, if we can obtain an~$A$ without relying on any ephemeral resources, then we are justified in having~$A$ as a persistent fact.
These two judgmental principles are expressed by the $\lab{copy}$ and $\lab{cut$^{\bang}_A$}$ rules:
\begin{mathpar}
  \infer[\lab{copy}]{\tctx ; \uctx, A ; \lctx' \seq C}{
    \tctx ; \uctx, A ; \lctx', A \seq C}
  \and
  \infer[\lab{cut$^{\bang}_A$}]{\tctx ; \uctx ; \lctx' \seq C}{
    \tctx ; \uctx ; \lctxe \seq A &
    \tctx ; \uctx, A ; \lctx' \seq C}
  \:.
\end{mathpar}

Finally, 
% Therefore, 
to match the new form of sequent,
% all previously presented rules are modified to uniformly include a context $\uctx$ in their premises and conclusion.
the other rules of linear logic are uniformly modified to include a context $\uctx$ in their premises and conclusion.
% There is no harm in duplicating or discarding persistent facts because they may not depend on ephemeral resources, %:
% % we would not be violating the linearity of resources.
% so the context $\uctx$ admits contraction and weakening (as well as exchange).
% % Therefore, the context $\uctx$ of persistent facts is treated as a set that also admits weakening.%
% % \footnote{Technically speaking, $\uctx$ is actually a multiset, with contraction being admissible as well.}
% Therefore, to match the new form of sequent, all previously presented rules are once again modified to include a \wc{validity}[\st{persistent}] context $\uctx$ in their premises and conclusion.
% % Once again, to match the new form of sequent, all previously presented rules are uniformly modified to include a \wc{validity}[persistent] context $\uctx$ in the premises and conclusion.
% For instance, the left rule for $A \lolli B$ is now
% \begin{equation*}
%   \infer[\llab{{\lolli}}]{\tctx ; \uctx ; \lmatch[']{\lctx'_A, A \lolli B} \seq C}{
%     \tctx ; \uctx ; \lctx'_A \seq A &
%     \tctx ; \uctx ; \lfill[']{B} \seq C}
%   \:.
% \end{equation*}


\subsubsection{Summary}\label{sec:summary-linear-logic}

For convenience, the rules described above are summarized in their complete form in \cref{fig:seq-jill}.%
\fxerror{\ [Decide whether to present $\bang A$ and $\monad{A}$ here.]}

% In this section, we briefly review a judgmental intuitionistic formulation of \citeauthor{Girard:TCS87}'s linear logic~\autocite*{Girard:TCS87}, a substructural logic of resources that is especially suited to modeling stateful systems.



\begin{figure}
  \begin{mathpar}
    \infer[\lab{id$_A$}]{\tctx ; \uctx ; A \seq A}{
      }
    \and
    \infer[\lab{cut$_A$}]{\tctx ; \uctx ; \lmatch[']{\lctx} \seq C}{
      \tctx ; \uctx ; \lctx \seq A &
      \tctx ; \uctx ; \lfill[']{A} \seq C}
    \\
    \infer[\rlab{{\lolli}}]{\tctx ; \uctx ; \lctx \seq A \lolli B}{
      \tctx ; \uctx ; \lctx, A \seq B}
    \and
    \infer[\llab{{\lolli}}]{\tctx ; \uctx ; \lmatch[']{\lctx'_A, A \lolli B} \seq C}{
      \tctx ; \uctx ; \lctx'_A \seq A &
      \tctx ; \uctx ; \lfill[']{B} \seq C}
    \\
    \infer[\rlab{{\tensor}}]{\tctx ; \uctx ; \lctx_1, \lctx_2 \seq A \tensor B}{
      \tctx ; \uctx ; \lctx_1 \seq A &
      \tctx ; \uctx ; \lctx_2 \seq B}
    \and
    \infer[\llab{{\tensor}}]{\tctx ; \uctx ; \lmatch[']{A \tensor B} \seq C}{
      \tctx ; \uctx ; \lfill[']{A, B} \seq C}
    \\
    \infer[\rlab{\one}]{\tctx ; \uctx ; \lctxe \seq \one}{
      }
    \and
    \infer[\llab{\one}]{\tctx ; \uctx ; \lmatch[']{\one} \seq C}{
      \tctx ; \uctx ; \lfill[']{} \seq C}
    \\
    \infer[\rlab{{\with}}]{\tctx ; \uctx ; \lctx \seq A \with B}{
      \tctx ; \uctx ; \lctx \seq A &
      \tctx ; \uctx ; \lctx \seq B}
    \\
    \infer[{\llab{{\with}}[1]}]{\tctx ; \uctx ; \lmatch[']{A \with B} \seq C}{
      \tctx ; \uctx ; \lfill[']{A} \seq C}
    \and
    \infer[{\llab{{\with}}[2]}]{\tctx ; \uctx ; \lmatch[']{A \with B} \seq C}{
      \tctx ; \uctx ; \lfill[']{B} \seq C}
    \\
    \infer[{\rlab{{\llor}}[1]}]{\tctx ; \uctx ; \lctx \seq A \llor B}{
      \tctx ; \uctx ; \lctx \seq A}
    \and
    \infer[{\rlab{{\llor}}[2]}]{\tctx ; \uctx ; \lctx \seq A \llor B}{
      \tctx ; \uctx ; \lctx \seq B}
    \and
    \infer[\llab{{\llor}}]{\tctx ; \uctx ; \lmatch[']{A \llor B} \seq C}{
      \tctx ; \uctx ; \lfill[']{A} \seq C &
      \tctx ; \uctx ; \lfill[']{B} \seq C}
    \\
    \infer[\rlab{\forall}]{\tctx ; \uctx ; \lctx \seq \univq x:\tau. A_x}{
      \tctx, x{:}\tau ; \uctx ; \lctx \seq A_x}
    \and
    \infer[\llab{\forall}]{\tctx ; \uctx ; \lmatch[']{\univq x:\tau. A_x} \seq C}{
      \tctx \seq M : \tau &
      \tctx ; \uctx ; \lfill[']{\subst{M/x}{A_x}} \seq C}
    \\
    \infer[\rlab{\exists}]{\tctx ; \uctx ; \lctx \seq \existq x:\tau. A_x}{
      \tctx \seq M : \tau &
      \tctx ; \uctx ; \lctx \seq \subst{M/x}{A_x}}
    \and
    \infer[\llab{\exists}]{\tctx ; \uctx ; \lmatch[']{\existq x:\tau. A_x} \seq C}{
      \tctx, x{:}\tau ; \uctx ; \lfill[']{A_x} \seq C}
    % \\
    % \infer[\rlab{\bang}]{\tctx ; \uctx ; \lctxe \seq \bang A}{
    %   \tctx ; \uctx ; \lctxe \seq A}
    % \and
    % \infer[\llab{\bang}]{\tctx ; \uctx ; \lmatch[']{\bang A} \seq C}{
    %   \tctx ; \uctx, A ; \lfill[']{} \seq C}
    \\
    \infer[\lab{copy}]{\tctx ; \uctx, A ; \lctx' \seq C}{
      \tctx ; \uctx, A ; \lctx', A \seq C}
    \and
    \infer[\lab{cut$^{\bang}_A$}]{\tctx ; \uctx ; \lctx' \seq C}{
      \tctx ; \uctx ; \lctxe \seq A &
      \tctx ; \uctx, A ; \lctx' \seq C}
  \end{mathpar}
  \caption{Sequent calculus rules for a fragment of \acl{JILL}~\autocite{Chang+:CMU03}.\label{fig:seq-jill}}
\end{figure}

\subsection{Proof search as computation: Bottom-up linear logic programming}\label{sec:linear-lp}

\begin{itemize}
\item Notion of transition obtained by reading sequent calculus left rules  (bipoles) bottom-up.
\end{itemize}

\subsection{Proof reduction as computation: Session-typed linear logic}\label{sec:async-sill}

Having seen a proof-reduction-as-computation correspondence between intuitionistic logic and functional computation (\cref{sec:proof-rec-as-comp}), it's natural to ask if there is a similar computational interpretation of the intuitionistic linear sequent calculus.
% as session-type discipline for concurrent processes:
% Giving session-typed concurrency a logical footing,
\Textcite{Caires+Pfenning:CONCUR10} along with Toninho~\autocite*{Caires+:TLDI12} have developed
% a Curry-Howard
an interpretation
% of the intuitionistic linear sequent calculus
in which proofs are processes, propositions are session types, and proof reduction is synchronous interprocess communication.

\Textcite{Toninho+:ESOP13} later extended this interpretation with recursive session types and integrated it into a functional language.
Here we review that integration, with one modification:
Instead of interpreting proof reductions as synchronous communication, we give an asynchronous operational semantics that is better suited to the proposed thesis, as we will see in \cref{sec:compile}, while still remaining faithful to the proof reductions~\autocite{DeYoung+:CSL12}.

\subsubsection{Session-typing judgment}\label{sec:sess-typing-judgm}

In a session-based model of concurrency, pairs of processes interact in well-defined sessions, with one process offering a service that its session partner uses.
Session types, pioneered by \textcite{Honda:CONCUR93}, describe the interaction protocol to which\fxnote{\ \st{a process adheres when offering its service}} the processes in that session must adhere.
% When processes interact according to the protocol, their states change
When processes interact, the session type changes: one process now offers, and the other uses, the continuation of the initial service.
The logical reading of session-based concurrency is linear logic exactly because it can express this change of state.
% \Citeauthor{Caires+:TLDI12}'s logical reading of session-based concurrency is as linear logic exactly because it can express this change of state.
% % It's for this reason that session-based concurrency is a computational interpretation of linear logic.

Because a process offers its service along a distinguished channel, the basic session-typing judgment is $P :: c{:}A$, meaning \enquote{process $P$ offers service of type $A$ along channel $c$}.
However, $P$ itself may rely on services offered by yet other processes, and so our session-typing judgment is, more generally, a linear sequent annotated as
\begin{equation*}
  \underbrace{c_1{:}A_1, \dotsc, c_n{:}A_n}_{\displaystyle \lctx} \seq P :: c{:}A \:,
\end{equation*}
meaning \enquote{Using services $A_i$ offered along channels $c_i$, the process $P$ offers service $A$ along channel $c$.}
The channels $c_i$ and $c$ must all be distinct and are binding occurrences with scope over the process $P$.

With this session-typing judgment, the inference rules of the linear sequent calculus become session-typing rules for concurrent processes.

% \fxerror{Recall from \cref{sec:judgmental-rules} that the sequent calculus for \ac{JILL} includes cut and identity rules that relate uses of resources to plans for obtaining resources.}

\subsubsection{Cut as composition}\label{sec:cut-as-composition}

Recall from \cref{sec:judgmental-rules} that the cut rule
% for \ac{JILL} 
composes a plan for obtaining resource $A$ with another plan that uses resource $A$:
\begin{equation*}
  \infer[\lab{cut$_A$}]{\lmatch[']{\lctx} \seq C}{
    \lctx \seq A &
    \lfill[']{A} \seq C}
  \:.
\end{equation*}
Because proofs are to be processes, this suggests that the process interpretation of the cut rule should compose a process that offers service $A$ with another process that uses service $A$.
The $\lab{cut$_A$}$ rule thus becomes a typing rule for process composition:
% annotated rule is thus
\begin{equation*}
  \infer[\lab{cut$_A$}]{\lctx, \lctx' \seq \mbind{\bv{c} <- \mspawn{P} <- \lctx; Q_{\bv{c}}} :: e{:}C}{
    \lctx \seq P :: c{:}A &
    \lctx', c{:}A \seq Q_c :: e{:}C}
  \:,
\end{equation*}
where $\mbind{\bv{c} <- \mspawn{P} <- \lctx; Q_{\bv{c}}}$ means \enquote{Spawn process $P$ that uses channels $\lctx$ to offer service along a fresh channel $c$, and then continue as process $Q_c$.}
The syntax is reminiscent of \haskell`do` notation for monadic computations, with the channel $\bv{c}$ being bound within $\mbind{\bv{c} <- \mspawn{P} <- \lctx; Q_{\bv{c}}}$.

\NewPredicate{\exec}{1}
To complete the description of $\mspawn{}$, we must make its operational semantics precise.
Rather than using \iacl{SOS}, it is convenient to describe the semantics as a forward-chaining linear logic program \autocites{Cervesato+:CMU02}{Pfenning:APLAS04}, in the style known as \iac{SSOS}.
In our \ac{SSOS}, we will use the linear proposition $\exec{P}$ to represent an executing process $P$.
The rule for executing a $\mspawn{}$ is
\begin{equation*}
  \exec{(\mbind{\bv{c} <- \mspawn{P} <- \lctx; Q_{\bv{c}}})}
    \lolli \monad{\existq c. \exec{P} \tensor \exec{Q_c}}
  \:.
\end{equation*}
Thus, to execute the $\mspawn{}$, we create a fresh channel $c$ and then execute the 
% offering process, $P$, and its client process, $Q_c$, in parallel.
process $P$, which offers a service along $c$, in parallel with its client process, $Q_c$.


\subsubsection{Additive conjunction as branching}\label{sec:addit-conj-as-branching}

\NewDocumentCommand{\inj}{m}{\mathtt{in}#1}
\NewDocumentCommand{\inl}{}{\inj{\mathtt{l}}}
\NewDocumentCommand{\inr}{}{\inj{\mathtt{r}}}

So far we have discussed only a judgmental principle that applies to all services; specific services are defined by the right and left rules of the logical connectives.

% \paragraph{Static semantics.}\label{sec:with-static-semantics}

Recall from \cref{sec:prop-conn} that the resource $A \with B$ gives a choice of resources $A$ and $B$.
The right rule for $A \with B$ was
\begin{equation*}
  \infer[\rlab{{\with}}]{\lctx \seq A \with B}{
    \lctx \seq A &
    \lctx \seq B}
  \:.
\end{equation*}
It says that to prove $A \with B$ we must prove both $A$ and $B$\fxnote{\ \st{(using the same resources $\lctx$)}} so that we are prepared for whichever of these two resources is eventually chosen.
%
Correspondingly, a process that offers service $A \with B$ gives its client a choice of services $A$ and $B$; the process must be prepared to offer whichever service the client chooses.
Based on this intuition, we interpret the~$\rlab{{\with}}$ rule as typing a binary guarded choice:
% Based on this intuition, we assign a binary guarded choice process to the $\rlab{{\with}}$ rule:
\begin{equation*}
  \infer[\rlab{{\with}}]{\lctx \seq \mcase{c}{\inl => P_1}{\inr => P_2} :: c{:}A \with B}{
    \lctx \seq P_1 :: c{:}A &
    \lctx \seq P_2 :: c{:}B}
  \:,
\end{equation*}
where $\mcase{c}{\inl => P_1}{\inr => P_2}$ means \enquote{Input either $\inl$ or $\inr$ along channel $c$, and then continue as process $P_1$ or $P_2$, respectively.}

Conversely, the client that uses service $A \with B$ must behave in a complementary way:
it should select either service $A$ or service $B$ and then, having notified the offering process of its choice (as $\inl$ or $\inr$), continue the session by using that service.
The left rules for type $A \with B$ are thus
\begin{mathpar}
  \infer[{\llab{{\with}}[1]}]{\lmatch[']{c{:}A \with B} \seq \moutputl{c.\inl; Q} :: e{:}C}{
    \lfill[']{c{:}A} \seq Q :: e{:}C}
  \and
  \infer[{\llab{{\with}}[2]}]{\lmatch[']{c{:}A \with B} \seq \moutputl{c.\inr; Q} :: e{:}C}{
    \lfill[']{c{:}B} \seq Q :: e{:}C}
  \:,
\end{mathpar}
where $\moutputl{c.\inj{\mathtt{l/r}}; Q}$ means \enquote{Send label $\inj{\mathtt{l/r}}$ along channel $c$ and then continue as process $Q$.}

% \paragraph{Operational semantics.}\label{sec:with-oper-semant}

Our intuition about the behavior of the guarded choice processes is made precise by their operational semantics.
First, the $\inl$ branch:
\NewPredicate{\msgc}[msg_c]{3}
\NewPredicate{\msgl}[msg_l]{3}
\begin{align*}
  &\exec{(\moutputl{c.\inl; Q})}
     \lolli \monad{\existq c'. \msgl{c,\inl,c'} \tensor \exec{(\subst{c'/c}{Q})}} \\
  %
  &\exec{(\mcase{c}{\inl => P_1}{\inr => P_2})} \tensor \msgl{c,\inl,c'}
     \lolli \monad{\exec{(\subst{c'/c}{P_1})}}
  \:.
\end{align*}
To execute the selection process $\moutputl{c.\inl; Q}$,
% we first send label $\inl$ along channel $c$, with a fresh channel $c'$ designated as the channel along which the session should continue.
we asynchronously send along channel $c$ a message containing label $\inl$ and a fresh channel $c'$,
% designated as the channel along which the session should continue
which is represented in the \ac{SSOS} as the proposition $\msgl{c,\inl,c'}$, and then immediately continue\fxnote{\ \st{the session}}
by executing $\subst{c'/c}Q$, \ie\ process $Q$ with channel $c'$ substituted for $c$.
When this message arrives, the destination process $\mcase{c}{\inl => P_1}{\inr => P_2}$ resumes execution as $\subst{c'/c}{P_1}$.
In this way, $c'$ is a fresh channel at which the offering process and its client rendezvous for the session continuation.
% This message is represented as the linear propostion $\msgl{c,\inl,c'}$.

If, instead of using a fresh channel, $c$ was reused as the session continuation channel, then consecutive selections along $c$ could be received out of order.
Because the communication is asynchronous, there would be no way to distinguish whether, for instance, $\msgl{c,\inl,\!}$ or $\msgl{c,\inr,\!}$ was sent first.
But, by sending the second message over a fresh continuation channel, the order is clear~\autocite{DeYoung+:CSL12}: $\msgl{c,\inl,c'}$ was sent before $\msgl{c',\inr,c''}$.

Although the operational semantics relies on fresh continuation channels, notice that the \emph{syntax} hides them from the programmer (hence the substitutions $\subst{c'/c}$ that appear in the semantics).
It would also be possible to explicitly incorporate continuation channels in the syntax (and thereby eliminate the substitutions), at the expense of readability, however.

The operational semantics of the $\inr$ branch is symmetric to that of the $\inl$ branch:
\begin{align*}
  &\exec{(\moutputl{c.\inr; Q})}
     \lolli \monad{\existq c'. \msgl{c,\inr,c'} \tensor \exec{(\subst{c'/c}{Q})}} \\
  %
  &\exec{(\mcase{c}{\inl => P_1}{\inr => P_2})} \tensor \msgl{c,\inr,c'}
     \lolli \monad{\exec{(\subst{c'/c}{P_2})}}
  \:.
\end{align*}

\paragraph{Practical considerations.}\label{sec:with-pract-cons}

To make the language more palatable for the programmer, we diverge slightly from a pure propositions-as-types interpretation of linear logic by including $n$-ary \emph{labeled} additive conjunctions $\nwith[_i]{{\ell_i}{A_i}}$ as a primitive.
The static and operational semantics are thus:
\begin{gather*}
  \infer[\rlab{{\with}}]{\lctx \seq \mcase{c}{\ell_i => P_i} :: c{:}\nwith[_i]{{\ell_i}{A_i}}}{
    \forall i\mathpunct{:}\;\;  \lctx \seq P_i :: c{:}A_i}
  \\[\jot]
  \infer[\llab{{\with}}]{\lmatch[']{c : \nwith[_i]{{\ell_i}{A_i}}} \seq \moutputl{c.\ell_k; Q} :: e{:}C}{
    \lfill[']{c{:}A_k} \seq Q :: e{:}C}
  \\[2\jot]
  \!\begin{aligned}
    &\exec{(\moutputl{c.\ell_k; Q})}
       \lolli \monad{\existq c'. \msgl{c,\ell_k,c'} \tensor \exec{(\subst{c'/c}{Q})}}
    \\
    &\exec{(\mcase{c}{\ell_i => P_i})} \tensor \msgl{c,\ell_k,c'}
       \lolli \monad{\exec{(\subst{c'/c}{P_k})}}
  \end{aligned}
\end{gather*}
Another possibility would be to simply treat $n$-ary labeled conjunctions as syntactic sugar for nested binary conjunctions, but this would turn out to introduce a communication overhead because we would be sending multiple $\inl$/$\inr$s separately rather than a single label $\ell_k$.


\subsubsection{Recursive session types and process definitions}\label{sec:recurs-sess-types}

Concurrent processes frequently exhibit unbounded or infinite, yet well-defined, behavior;
for instance, we may wish to have a counter that offers an increment service indefinitely.
To this end, \textcite{Toninho+:coind13} are currently extending the \ac{SILL} type theory with inductive and coinductive session types.
Meanwhile, however, we must content ourselves to depart from a pure Curry-Howard correspondence and instead rely on general recursion.

Session types thus include general recursive types, $\mu t.A$, and type variables, $t$.
The type $\mu t.A$ is interpreted equi-recursively, being identified with its unfolding, namely $\subst{(\mu t.A)/t}{A}$.
Processes correspondingly include mutually recursive process definitions, via \msill`letrec`, and process variables, $X$.

\let\pctx\tctx
We
% first step is to introduce process variables, $X$, and 
extend the session-typing judgment with a context, $\pctx$, of process variable typings.
% Because a process is typed according to the services that it uses and offers, process variables are typed as $X : \ctxmonad{A <- \vec{B}}$, meaning that process $X$ can offer service $A$ if provided with channels along which services $\vec{B}$ are offered.
Because a process is typed according with a sequent of services that it uses and offers, process variables are typed as ${X : \ctxmonad{A <- \vec{B}}}$ if process $X$ can offer service $A$ 
% when provided with channels along which services $\vec{B}$ are offered.
by using services $\vec{B}$.
When channels of appropriate types are available, the process $X$ can be called:
%  If channels of the types in $\lctx$ are available, then process $X$ can be called with those channels.
\begin{equation*}
  \infer[\lab{call}]{\tctx, X{:}\ctxmonad{A <- \vec{B}} ; \lctx \seq \mbind{c <- X <- \vec{d}} :: c{:}A}{
    \lctx = d_1{:}B_1, \dotsc, d_n{:}B_n}
  \:.
\end{equation*}
A common idiom is $\mbind{\bv{c} <- \mspawn{(\mbind{\bv{c} <- X <- \vec{d}})} <- \vec{d}; Q_{\bv{c}}}$, which spawns a call to $X$ that is run in parallel with some process $Q_c$.
We will frequently abbreviate this with the syntactic sugar $\mbind{\bv{c} <- X <- \vec{d}; Q_{\bv{c}}}$.

% Mutually recursive process definitions add process variables to the context.
% Process variables are added to the context to allow for mutual recursion.
In mutually recursive process definitions,
% , the programmer declares each process with a type that must be checked.
the process bodies may refer to any of the mutually recursive processes via process variables.
The typing rule is
\begin{gather*}
  \infer[\lab{letrec}]{\pctx ; \lctx \seq \mletrec{\mprocdef{c_1 <- X_1 <- \vec{d_1} = P_1} and \dotsb and \mprocdef{c_n <- X_n <- \vec{d_n} = P_n}}{Q} :: c{:}C}{
    \forall i\mathpunct{:}\;\; \pctx' ; d_{i,1}{:}B_{i,1}, \dotsc, d_{i,k_i}{:}B_{i,k_i} \seq P_i :: c_i{:}A_i &&
    \pctx' ; \lctx \seq Q :: c{:}C} \\
\shortintertext{where}
  \pctx' = \pctx, X_1{:}\ctxmonad{A_1 <- \vec{B_1}}, \dotsc, X_n{:}\ctxmonad{A_n <- \vec{B_n}}
  \:.
\end{gather*}

Now, having presented recursion, we can finally give a simple example program.


\subsubsection{Example: Binary counter}\label{sec:exampl-binary-count}

% As an example session-typed program, we can implement a simple counter as shown in \cref{fig:counter-inc}.%
We can implement a simple session-typed counter as shown in \cref{fig:counter-inc}.%
\footnote{This example is adapted from one by \textcite{Toninho+:ESOP13}.}
%
  \begin{sillcode}[
    caption={A simple binary counter supporting an increment operation},%
    label={fig:counter-inc},%
    gobble=4
  ]
    stype Counter = &{ inc: Counter }
    
    eps : {|- c:Counter}
    c <- eps =
    { case c of
        inc => d <- eps;
               c <- bit1 <- d }
    
    bit0 : {d:Counter |- c:Counter}
    c <- bit0 <- d =
    { case c of
        inc => c <- bit1 <- d }
    
    bit1 : {d:Counter |- c:Counter}
    c <- bit1 <- d =
    { case c of
        inc => d.inc;
               c <- bit0 <- d }
  \end{sillcode}
%
The counter is a linear network of \msill`bit0` and \msill`bit1` processes, one for each bit in the binary representation of the counter's value, and is terminated at the most significant end with an \msill`eps` process.
For instance, the process network \msill`<- bit0 <- bit1 <- eps`\fxnote{\ [Write in opposite order?]} represents a counter with value $2$.

The counter offers a very simple service: the client may only choose to increment the counter, with the same service being offered recursively after the increment.
% The counter thus offers a service of type \msill`Counter` declared as \msill`stype Counter = &{ inc: Counter }`.
This service, \msill`Counter`, is therefore a recursive additive conjunction
% The service is of type \msill`Counter`,
declared in the concrete syntax as \msill`stype Counter = &{ inc: Counter }`.
The \msill`eps` process offers this service outright, and thus has type \msill`{|- Counter}`.
% , whereas the \msill`bit0` and \msill`bit1` processes use the service offered by their more significant neighbors.
The \msill`bit0` and \msill`bit1` processes, on the other hand, use the service offered by their more significant neighbors, and thus have type \msill`{Counter |- Counter}`.

The process definitions of \msill`eps`, \msill`bit0`, and \msill`bit1` are mutually recursive.
When an \msill`eps` process receives an \msill`inc` message, it creates a new most significant bit by spawning a new \msill`eps` process and then making a recursive call to a \msill`bit1` process.
% that uses the service offered by the new \msill`eps`.
When a \msill`bit0` process receives an \msill`inc`, the bit is flipped by way of a recursive call to a \msill`bit1` process.
Lastly, when a \msill`bit1` process receives an \msill`inc`, the bit is flipped and a carry is propagated; this is accomplished by first sending \msill`inc` along channel \msill`d` to the \msill`Counter` offered by the next more significant bit and then making a recursive call to a \msill`bit0` process.

Informally, we can see that the \msill`inc` operation just described respects a counter's denotation: whenever a counter representing $n$ is incremented, the resulting counter represents $n+1$.
\fxnote{Dependent types?}


\subsubsection{Additive disjunction as choice}\label{sec:addit-disj-as-choice}

In the intuitionistic linear sequent calculus, additive disjunction, $A \llor B$, is dual to additive conjunction, $A \with B$.
We should expect this duality to also appear in the process assignment.
% Because the additive disjunction $A \llor B$ and additive conjunction $A \with B$ are dual, their process assignments are also dual:
Whereas a process of type $A \with B$ offers its client a choice of services $A$ and $B$, a process of type $A \llor B$ chooses between offering service $A$ or service $B$ to its client.
The client waits to be notified of the offering process's choice and then uses that service.
\begin{mathpar}
  \infer[{\rlab{{\llor}}[1]}]{\lctx \seq \moutputl{c.\inl; P} :: c{:}A \llor B}{
    \lctx \seq P :: c{:}A}
  \and
  \infer[{\rlab{{\llor}}[2]}]{\lctx \seq \moutputl{c.\inr; P} :: c{:}A \llor B}{
    \lctx \seq P :: c{:}B}
  \and
  \infer[\llab{{\llor}}]{\lmatch[']{c{:}A \llor B} \seq \mcase{c}{\inl => Q_1}{\inr => Q_2} :: e{:}C}{
    \lmatch[']{c{:}A} \seq Q_1 :: e{:}C &
    \lmatch[']{c{:}B} \seq Q_2 :: e{:}C}
\end{mathpar}
Once again, to make the language more convenient for the programmer, we include $n$-ary labeled additive disjunctions $\nllor[_i]{{\ell_i}{A_i}}$.
The typing rules are thus more generally
\begin{mathpar}
  \infer[\rlab{{\llor}}]{\lctx \seq \moutputl{c.\ell_k; P} :: c : \nllor[_i]{{\ell_i}{A_i}}}{
    \lctx \seq P :: c{:}A_k}
  \and
  \infer[\llab{{\llor}}]{\lmatch[']{c : \nllor[_i]{{\ell_i}{A_i}}} \seq \mcase{c}{\ell_i => Q_i} :: e{:}C}{
    \forall i\mathpunct{:}\;\;  \lmatch[']{c{:}A_i} \seq Q_i :: e{:}C}
  \mathrlap{\:.}
\end{mathpar}
The operational semantics for these guarded choice constructs was already given in \cref{sec:addit-conj-as-branching}.


\subsubsection{Example: Binary counter with increment and decrement operations}\label{sec:exampl-binary-count-1}

\Cref{lst:counter-inc-dec} shows a counter that takes advantage of additive disjunction to support a truncated decrement operation.
%
\begin{sillcode}[
  caption={A binary counter supporting increments and decrements},
  label={lst:counter-inc-dec},
  floatplacement=tb,
  gobble=2
]
  stype Counter = &{ inc: Counter ,
                     dec: +{ zero: Counter , succ: Counter } }
  
  eps : {|- c:Counter}
  c <- eps =
  { case c of
      inc => d <- eps;
             c <- bit1 <- d
    | dec => c.zero;
             c <- eps }
  
  bit0 : {d:Counter |- c:Counter}
  c <- bit0 <- d =
  { case c of
      inc => c <- bit1 <- d
    | dec => d.dec;
             (case d of
                zero => c.zero;
                        c <- bit0 <- d
              | succ => c.succ;
                        c <- bit1 <- d) }
  
  bit1 : {d:Counter |- c:Counter}
  c <- bit1 <- d =
  { case c of
      inc => d.inc;
             c <- bit0 <- d
    | dec => c.succ;
             c <- bit0 <- d }
\end{sillcode}%
%
According to the type declaration, a process offering the \msill`Counter` service gives its client a choice of increment or decrement services.
If the client chooses to decrement, the offering process will choose to reply with either \msill`zero` or \msill`succ` and then recursively offer the \msill`Counter` service.
% The type is thus declared as
% \begin{sillcode*}[xleftmargin=\parindent, gobble=2]
%   stype Counter = &{ inc: Counter ,
%                      dec: +{ zero: Counter , succ: Counter } }
% \end{sillcode*}

As implemented, the counter gives \msill`zero` and leaves the process network unchanged if the counter represents $0$;
if it represents some $N > 0$, then the counter gives \msill`succ` after decrementing to $N - 1$.
However, these properties are not enforced by the type \msill`Counter`.
With an appropriate dependent session type, these properties could be enforced, but for simplicity we use the simple type here.

\subsubsection{Identity as forwarding}\label{sec:ident-as-forw}

Also recall the identity principle for \ac{JILL}, which states that one way to obtain a resource is to directly use an existing resource.
Under the process interpretation, a process can offer service $A$ by acting as an forwarding intermediary between its clients and another process that offers service $A$.
The $\lab{id$_A$}$ rule thus types a forwarding process between two channels:
\begin{equation*}
  \infer[\lab{id$_A$}]{d{:}A \seq \mfwd{c <- d} :: c{:}A}{
    }
  \:.
\end{equation*}
Rather than making the forwarding explicit in the operational semantics, we can simply equate the two channels:
\begin{equation*}
  \exec{(\mfwd{c <- d})} \lolli \monad{c \eq d}
\end{equation*}


\subsubsection{Other session types}\label{sec:lolli-as-input-tensor-as-output}

In addition to the session types already mentioned, \ac{SILL} includes session types corresponding to the other connectives of linear logic.
% In addition to processes that send and receive labels and are typed with additive conjunctions and disjunctions, \ac{SILL} supports processes that exchange functional values.

The first-order quantifiers type processes that exchange functional values.
% These are typed by the rules for first-order quantifiers.
A process offering service $\univq x:\tau. A_x$ (or using service $\existq x:\tau. A_x$) first inputs a value $x$ of functional type $\tau$ and then offers (resp., uses) service $A_x$.
% , where $A_x$ may depend on $x$.
Dually, a process offering service $\existq x:\tau. A_x$ (or using service $\univq x:\tau. A_x$) asynchronously outputs the value of some functional term $M$\fxnote{\ \st{a functional value}} of type $\tau$ and then offers (resp., uses) service $\subst{M/x}{A_x}$.
The first order quantifiers are thus dependent session types; in the non-dependent case, we write the types as $\tau \land A$ and $\tau \imp A$.
% Processes that send and receive funcitonal values are written as $\minput{x <- input c; P}$ and $\moutputv{c}{M}{Q}$.
The syntax for value inputs and outputs is $\minput{\bv{x} <- input c; P_{\bv{x}}}$ and $\moutputv{c}{M}{Q}$.

Linear implications and multiplicative conjunctions type processes that send and receive channels.
% \Ac{SILL} also includes linear implication and multiplicative conjunction as session types.
A process offering service $A \lolli B$ (or using service $A \tensor B$) first inputs a channel of type $A$ and then offers (resp., uses) service $B$.
Dually, a process offering service $A \tensor B$ (or using service $A \lolli B$) asynchronously outputs a fresh channel of type $A$ and then offers (resp., uses) service $B$.
% Similarly to the quantifiers, the left and right rules for linear implication and multiplicative conjunction thus type channel inputs and outputs, which are written as $\minput{d <- input c; P}$ and $\moutputc{c}{d <- P}{Q}$.
The syntax for channel inputs and outputs is $\minput{\bv{d} <- input c; P_{\bv{d}}}$ and $\moutputc{c}{\bv{d} <- Q_{\bv{d}}}{R}$.

Since value and channel inputs and outputs are not important to the remainder of this proposal, the reader who is interested in further details of their static and operational semantics should refer to the papers by \textcites{Toninho+:ESOP13}{Toninho+:PPDP11}.


\subsubsection{Linear implication as input}\label{sec:linear-implication-as-input}

Recall the sequent calculus right rule for linear implication:
\begin{equation*}
  \infer[\rlab{{\lolli}}]{\lctx \seq A \lolli B}{
    \lctx, A \seq B} \:.
\end{equation*}
% It says that to obtain ${A \lolli B}$ we can obtain $B$ while presuming to have $A$.
It says that to prove $A \lolli B$ we should presume to have an $A$ and then show how to use it to obtain $B$.
Correspondingly, a process that offers service $A \lolli B$ should first input a channel offering service $A$ and then continue the session by using that service to offer service $B$.
Based on this intuition, we assign an input process to the $\rlab{{\lolli}}$ rule:
\begin{equation*}
  \infer[\rlab{{\lolli}}]{\lctx \seq \minput{d <- input c; P_d} :: c{:}A \lolli B}{
    \lctx, d{:}A \seq P_d :: c{:}B} \:,
\end{equation*}
where the syntax $\minput{d <- input c; P_d}$ means \enquote{Input channel $d$ along channel $c$ and then continue as process $P_d$.}

The left rule for linear implication uses the service offered by the right rule, so it should be a matching output:
\begin{equation*}
  \infer[\llab{{\lolli}}]{\lmatch[']{\lctx'_A, c{:}A \lolli B} \seq \moutputc{c}{d <- Q_d}{R} :: e{:}C}{
    \lctx'_A \seq Q_d :: d{:}A &
    \lfill[']{c{:}B} \seq R :: e{:}C} \:,
\end{equation*}
where the syntax $\moutputc{c}{d <- Q_d}{R}$ means \enquote{Output a fresh channel $d$ along channel $c$, spawn process $Q_d$ that interacts along $d$, and then continue as process $R$.}

\subsubsection{Multiplicative conjunction as output}\label{sec:mult-conj-as-output}

Once again, because there is a flavor of duality between multiplicative conjunction and linear implication, their prociss assignments are also dual:
% In the sequent calculus for intuitionistic linear logic, multiplicative conjunction, $A \tensor B$, is dual to linear implication.
% We should expect this duality to also appear in the process assignment.
Whereas a process of type $A \lolli B$ offers an input of an $A$ and then continues as $B$, a process of type $A \tensor B$ offers an output of an $A$ and then continues as $B$:
\begin{mathpar}
  \infer[\rlab{{\tensor}}]{\lctx_1, \lctx_2 \seq \moutputc{c}{d <- P_d}{Q} :: c{:}A \tensor B}{
    \lctx_1 \seq P_d :: d{:}A &
    \lctx_2 \seq Q :: c{:}B}
  \and
  \infer[\llab{{\tensor}}]{\lmatch[']{c{:}A \tensor B} \seq \minput{d <- input c; R} :: e{:}C}{
    \lfill[']{d{:}A, c{:}B} \seq R :: e{:}C} \:.
\end{mathpar}

Because the operational semantics is asynchronous

\begin{align*}
  &\exec{(\moutputc{c}{d <- Q_d}{R})}
     \lolli \monad{\existq d,c'. \msgc{c,d,c'} \tensor \exec{Q_d} \tensor \exec{(\subst{c'/c}{R})}} \\
  %
  &\exec{(\minput{d <- input c; P_d})} \tensor \msgc{c,d,c'}
     \lolli \monad{\exec{(\subst{c'/c}{P_d})}}
\end{align*}


\begin{itemize}
\item Present monadic language only?  Disadvantage is that proof reduction is not quite as clear or simple to see since it involves run-time typing.
\end{itemize}




\subsubsection{Appendix: dependently typed counter}\label{sec:append-depend-typed}

\begin{pyglist}[language=text,
    captionbgcolor=gray,
    listingnamefont=\sffamily\bfseries\color{white},
    captionfont=\sffamily\color{white},
    fvset={frame=bottomline, framerule=0.8ex, rulecolor=\color{gray}},
    caption={A dependently typed binary counter supporting increments},
    label={fig:dep-counter-inc},
    gobble=4]
    stype Counter N = &{ inc: Counter (s N) ,
                         dec: +{ succ: Counter (N-1) , fail: Counter N } }

    stype Counter 0     = &{ inc: Counter (s 0)     , dec: +{ fail: Counter 0 } }
        | Counter (s N) = &{ inc: Counter (s (s N)) , dec: +{ succ: Counter N } }
    
    stype Counter 0     = &{ inc: Counter (s 0)     , dec: Counter 0 }
        | Counter (s N) = &{ inc: Counter (s (s N)) , dec: Counter N }
    
    eps : {|- Counter 0}
    c <- eps =
    { case c of
        inc => e <- eps;
               c <- bit1 <- e
      | dec => c.fail;
               c <- eps }
    
    bit0 : {Counter N |- Counter 2N}
    c <- bit0 <- d =
    { case c of
        inc => c <- bit1 <- d
      | dec => d.dec;
               case d of
                 succ => c.succ;
                         c <- bit1 <- d
               | fail => c.fail;
                         c <- bit0 <- d }

    c <- bit0 N <- d =
    { case c of
        inc => c <- bit1 <- d
      | dec => case N of
                 s N' => d.dec;
                         c <- bit1 <- d
               | 0 => c <- bit0 <- d }                      
    
    bit1 : {Counter N |- Counter (s 2N)}
    c <- bit1 <- d =
    { case c of
        inc => d.inc;
               c <- bit0 <- d
      | dec => c.succ;
               c <- bit0 <- d }
  \end{pyglist}



\subsection{Ordered logic}\label{sec:ordered-logic}

As described in \cref{sec:introduction}, this thesis proposes to show that session types form a bridge between notions of concurrency that arise in proof-search-as-computation and proof-reduction-as-computation interpretations of linear logic.
Proof search in linear logic appears a bit too complex to tackle outright.
So, in this proposal, we turn our attention to ordered logic.

In linear logic, the order of hypotheses is unimportant; $A \tensor B \lolli B \tensor A$ is provable, for example.
Pure ordered logic, on the other hand, is a restriction of linear logic in which order matters:
in addition to rejecting contraction and weakening, ordered logic also rejects the structural principle of exchange.
The basic sequent is
\begin{equation*}
  \underbrace{A_1, \dotsc, A_n}_{\displaystyle \octx} \seq A \:.
\end{equation*}

Having rejected {??}, we must reconsider the various forms of proposition.


\NewDocumentCommand{\ofrm}{m}{\Theta\{#1\}}
\begin{figure}
  \begin{mathpar}
    \infer[\lab{id}]{P \seq P}{
      }
    \\
    \infer[\rlab{{\rimp}}]{\octx \seq A \rimp B}{
      \octx, A \seq B}
    \and
    \infer[\llab{{\rimp}}]{\ofrm{A \rimp B, \octx'} \seq J}{
      \octx' \seq A &
      \ofrm{B} \seq J}
    \\
    \infer[\rlab{{\limp}}]{\octx \seq A \limp B}{
      A, \octx \seq B}
    \and
    \infer[\llab{{\limp}}]{\ofrm{\octx', A \limp B} \seq J}{
      \octx' \seq A &
      \ofrm{B} \seq J}
    \\
    \infer[\rlab{{\with}}]{\octx \seq A \with B}{
      \octx \seq A &
      \octx \seq B}
    \and
    \infer[{\llab{{\with}}[1]}]{\ofrm{A \with B} \seq J}{
      \ofrm{A} \seq J}
    \and
    \infer[{\llab{{\with}}[2]}]{\ofrm{A \with B} \seq J}{
      \ofrm{B} \seq J}
    \\
    \infer[\rlab{{\fuse}}]{\octx_1, \octx_2 \seq A \fuse B}{
      \octx_1 \seq A &
      \octx_2 \seq B}
    \and
    \infer[\llab{{\fuse}}]{\ofrm{A \fuse B} \seq J}{
      \ofrm{A, B} \seq J}
    \\
    \infer[\rlab{\one}]{\octxe \seq \one}{
      }
    \and
    \infer[\llab{\one}]{\ofrm{\one} \seq J}{
      \ofrm{\octxe} \seq J}
  \end{mathpar}
  \begin{mathpar}
    \infer-[\lab{id$_A$}]{A \seq A}{
      }
    \and
    \infer-[\lab{cut$_A$}]{\ofrm{\octx} \seq J}{
      \octx \seq A &
      \ofrm{A} \seq J}
  \end{mathpar}
  \caption{Sequent calculus rules for ordered logic~\autocite{Polakow+Pfenning:MFPS99,Simmons:CMU12}.}
\end{figure}




\begin{itemize}
\item Should I give a brief introduction to linear logic here?  Or, is this overkill for committee members?
\item Present ordered logic in its own right here, or present ordered logic only in the context of bottom-up logic programming?
\end{itemize}

\subsection{Bottom-up ordered logic programming}\label{sec:ordered-lp}

\NewPredicate{\eps}{0}
\NewPredicate{\bitz}[bit_0]{0}
\NewPredicate{\bito}[bit_1]{0}
\ExplSyntaxOn
\NewDocumentCommand{\bit}{m}{
  \int_case:nnF {#1}
    {
      {0} {\bitz}
      {1} {\bito}
    }
    { Error! }
}
\ExplSyntaxOff
\NewPredicate{\inc}{0}

\begin{align*}
  &\eps \fuse \inc \lrimp \eps \fuse \bit{1} \\
  &\bit{0} \fuse \inc \lrimp \bit{1} \\
  &\bit{1} \fuse \inc \lrimp \inc \fuse \bit{0}
\end{align*}

\begin{itemize}
\item Example: binary counter with increment.
\end{itemize}


%%% Local Variables:
%%% TeX-master: "proposal"
%%% End:
